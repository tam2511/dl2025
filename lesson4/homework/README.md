# Домашнее задание: Multi-Branch MLP для мультиклассовой классификации

## Задача

Реализовать multi-branch модель для мультиклассовой классификации на датасете Wine Quality и добиться **F1 score ≥ 40%**.

## Структура задания

Заполните ноутбук `multi_branch_classification.ipynb`, реализовав методы, помеченные `# TODO`.

## Требования

### 1. Multi-Branch модель

Реализуйте модель с **тремя параллельными ветками** (branches), результаты которых объединяются:

- **Branch 1: Bottleneck блок** - сужение размерности (dim → dim//4 → dim) (уже реализовано)
- **Branch 2: Inverted Bottleneck блок** - расширение размерности (dim → dim*4 → dim) (уже реализовано)
- **Branch 3: Regular блок** - обычный residual без bottleneck (dim → hidden_dim → dim) (уже реализовано)

**Ваша задача**: Реализовать `MultiBranchMLP` - модель, которая:
1. Принимает вход и проецирует в hidden_dim
2. Пропускает через три параллельные ветки (каждая из num_blocks блоков своего типа)
3. Объединяет результаты через конкатенацию (`concat`) или суммирование (`sum`)
4. Проецирует в выходную размерность
5. Можете добавить identety skip connection (опционально)

### 2. Финальное качество **F1 score (macro) ≥ 40%**

- Проанализируйте распределение классов в датасете
- Реализуйте **weighted cross-entropy loss** с весами, обратно пропорциональными частоте классов (или подберите в зависимости от метрик обучения)

Подберите оптимальные значения:
- **Глубина модели** (num_blocks): попробуйте 2, 4, 6, 8 блоков
- **Ширина модели** (hidden_dim): попробуйте 64, 128, 256
- **Learning rate**: попробуйте 1e-2, 1e-3, 1e-4
- **Оптимизатор**: сравните Adam, AdamW, SGD (с momentum)

Также отслеживайте:
- Accuracy
- F1 score для каждого класса
- Confusion matrix

- Используйте `BaseLightningModule` из `../../lesson3/seminar/lightning_module.py`
- Для вычисления весов классов используйте `sklearn.utils.class_weight.compute_class_weight`
- Начните с простой конфигурации и постепенно усложняйте
- Используйте early stopping для предотвращения переобучения
