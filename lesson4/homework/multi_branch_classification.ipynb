{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: Multi-Branch MLP для Wine Quality\n",
    "\n",
    "**Цель**: Реализовать multi-branch модель и добиться F1 score ≥ 40%\n",
    "\n",
    "**Задачи**:\n",
    "1. Реализовать три типа блоков: Bottleneck, Inverted Bottleneck, Regular\n",
    "2. Создать Multi-Branch архитектуру\n",
    "3. Использовать weighted loss для борьбы с дисбалансом классов\n",
    "4. Подобрать оптимальные гиперпараметры (глубина, ширина, lr, оптимизатор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sys\n",
    "sys.path.append('../../lesson3/seminar')\n",
    "from wine_quality_data import WineQualityDataModule\n",
    "from lightning_module import BaseLightningModule\n",
    "from utils import set_seed\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и анализ данных\n",
    "\n",
    "Загрузим Wine Quality датасет и проанализируем распределение классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "dm = WineQualityDataModule(batch_size=128)\n",
    "dm.setup()\n",
    "\n",
    "print(f'Train samples: {len(dm.train_dataset)}')\n",
    "print(f'Val samples: {len(dm.val_dataset)}')\n",
    "print(f'Input dim: {dm.input_dim}')\n",
    "print(f'Num classes: {dm.n_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Анализ дисбаланса классов\n",
    "\n",
    "Проанализируйте распределение классов и вычислите веса для weighted loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Получите метки классов из train_dataset\n",
    "# Hint: dm.train_dataset[i] возвращает (X, y)\n",
    "train_labels = None  # TODO\n",
    "\n",
    "# TODO: Постройте гистограмму распределения классов\n",
    "# plt.hist(...)\n",
    "\n",
    "# TODO: Вычислите веса классов используя compute_class_weight\n",
    "# Веса должны быть обратно пропорциональны частоте класса (однако это может не работать, поэтому можете подобрать сами)\n",
    "class_weights = None  # TODO\n",
    "\n",
    "print(f'Class weights: {class_weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Реализация блоков\n",
    "\n",
    "Реализуйте три типа блоков:\n",
    "- **Bottleneck**: dim → dim//4 → dim (сужение)\n",
    "- **Inverted Bottleneck**: dim → dim*4 → dim (расширение)\n",
    "- **Regular**: dim → hidden_dim → dim (обычный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseMLPBlock(nn.Module, ABC):\n",
    "    \"\"\"Базовый класс для MLP блока\"\"\"\n",
    "    def __init__(self, dim, activation='gelu', dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.activation = {'relu': nn.ReLU(), 'gelu': nn.GELU(), 'swish': nn.SiLU()}.get(activation, nn.GELU())\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else None\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class BottleneckBlock(BaseMLPBlock):\n",
    "    \"\"\"\n",
    "    Bottleneck блок: dim → dim//4 → dim\n",
    "    \n",
    "    Сужает размерность в 4 раза, затем восстанавливает.\n",
    "    Использует residual connection для стабильного обучения.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, activation='gelu', dropout=0.0):\n",
    "        super().__init__(dim, activation, dropout)\n",
    "        \n",
    "        # Bottleneck dimension (сужение в 4 раза)\n",
    "        self.bottleneck_dim = max(dim // 4, 1)\n",
    "        \n",
    "        # Линейные слои: dim → bottleneck_dim → dim\n",
    "        self.fc1 = nn.Linear(self.dim, self.bottleneck_dim)\n",
    "        self.fc2 = nn.Linear(self.bottleneck_dim, self.dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # Bottleneck pathway\n",
    "        out = self.fc1(x)\n",
    "        out = self.activation(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        return out + identity\n",
    "\n",
    "class InvertedBottleneckBlock(BaseMLPBlock):\n",
    "    \"\"\"\n",
    "    Inverted Bottleneck блок: dim → dim*4 → dim\n",
    "    \n",
    "    Расширяет размерность в 4 раза, затем сжимает обратно.\n",
    "    Использует residual connection для стабильного обучения.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, expansion_factor=4, activation='gelu', dropout=0.0):\n",
    "        super().__init__(dim, activation, dropout)\n",
    "        \n",
    "        # Expanded dimension (расширение в 4 раза)\n",
    "        self.expanded_dim = dim * expansion_factor\n",
    "        \n",
    "        # Линейные слои: dim → expanded_dim → dim\n",
    "        self.fc1 = nn.Linear(self.dim, self.expanded_dim)\n",
    "        self.fc2 = nn.Linear(self.expanded_dim, self.dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # Inverted bottleneck pathway\n",
    "        out = self.fc1(x)\n",
    "        out = self.activation(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        return out + identity\n",
    "\n",
    "class RegularBlock(BaseMLPBlock):\n",
    "    \"\"\"\n",
    "    Regular блок: dim → hidden_dim → dim\n",
    "    \n",
    "    Обычный двухслойный MLP с residual connection.\n",
    "    hidden_dim по умолчанию равен dim * 2.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, hidden_dim=None, activation='gelu', dropout=0.0):\n",
    "        super().__init__(dim, activation, dropout)\n",
    "        \n",
    "        # Hidden dimension (по умолчанию в 2 раза больше)\n",
    "        self.hidden_dim = hidden_dim if hidden_dim else dim * 2\n",
    "        \n",
    "        # Линейные слои: dim → hidden_dim → dim\n",
    "        self.fc1 = nn.Linear(self.dim, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # Regular pathway\n",
    "        out = self.fc1(x)\n",
    "        out = self.activation(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        return out + identity\n",
    "\n",
    "# Тестируем блоки\n",
    "print('✓ Блоки успешно определены!')\n",
    "print()\n",
    "\n",
    "# Проверим размерности\n",
    "test_x = torch.randn(4, 64)\n",
    "print('Тестирование блоков с размерностью 64:')\n",
    "print(f'  Input shape: {test_x.shape}')\n",
    "\n",
    "bottleneck = BottleneckBlock(64)\n",
    "print(f'  BottleneckBlock output: {bottleneck(test_x).shape}')\n",
    "\n",
    "inverted = InvertedBottleneckBlock(64)\n",
    "print(f'  InvertedBottleneckBlock output: {inverted(test_x).shape}')\n",
    "\n",
    "regular = RegularBlock(64)\n",
    "print(f'  RegularBlock output: {regular(test_x).shape}')\n",
    "\n",
    "# Подсчитаем параметры\n",
    "print()\n",
    "print('Количество параметров:')\n",
    "print(f'  BottleneckBlock: {sum(p.numel() for p in bottleneck.parameters()):,}')\n",
    "print(f'  InvertedBottleneckBlock: {sum(p.numel() for p in inverted.parameters()):,}')\n",
    "print(f'  RegularBlock: {sum(p.numel() for p in regular.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Branch модель\n",
    "\n",
    "Реализуйте модель с тремя параллельными ветками.\n",
    "\n",
    "**Архитектура**:\n",
    "```\n",
    "         Input\n",
    "           |\n",
    "      projection\n",
    "           |\n",
    "      ┌────┼────┐\n",
    "      │    │    │\n",
    "  Bottleneck  Inverted  Regular\n",
    "   Branch      Branch    Branch\n",
    "      │    │    │\n",
    "      └────┼────┘\n",
    "           |\n",
    "      Concatenate/Sum\n",
    "           |\n",
    "      projection\n",
    "           |\n",
    "        Output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBranchMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Branch MLP с тремя параллельными ветками.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: размерность входа\n",
    "        hidden_dim: размерность скрытых слоев\n",
    "        output_dim: размерность выхода (число классов)\n",
    "        num_blocks: количество блоков в каждой ветке\n",
    "        dropout: вероятность dropout\n",
    "        combine_mode: способ объединения веток ('concat' или 'sum')\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_blocks=4,\n",
    "        dropout=0.1,\n",
    "        combine_mode='concat'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.combine_mode = combine_mode\n",
    "        \n",
    "        # TODO: Входная проекция\n",
    "        # self.input_proj = ...\n",
    "        \n",
    "        # TODO: Создайте три ветки (branches)\n",
    "        # Branch 1: num_blocks блоков BottleneckBlock\n",
    "        # Branch 2: num_blocks блоков InvertedBottleneckBlock\n",
    "        # Branch 3: num_blocks блоков RegularBlock\n",
    "        # Используйте nn.ModuleList\n",
    "        \n",
    "        # self.bottleneck_branch = ...\n",
    "        # self.inverted_branch = ...\n",
    "        # self.regular_branch = ...\n",
    "        \n",
    "        # TODO: Выходная проекция\n",
    "        # Если combine_mode == 'concat', то вход будет hidden_dim * 3\n",
    "        # Если combine_mode == 'sum', то вход будет hidden_dim\n",
    "        # self.output_proj = ...\n",
    "        \n",
    "        pass  # TODO: удалите pass после реализации\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Реализуйте forward pass\n",
    "        # 1. Входная проекция\n",
    "        # 2. Пропустите через каждую ветку\n",
    "        # 3. Объедините результаты (concat или sum)\n",
    "        # 4. Выходная проекция\n",
    "        pass  # TODO\n",
    "\n",
    "print('Multi-Branch модель определена!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Код обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    dm,\n",
    "    class_weights=None,\n",
    "    max_epochs=50,\n",
    "    lr=1e-3,\n",
    "    optimizer_type='adam'\n",
    "):\n",
    "    \"\"\"\n",
    "    Обучает модель с weighted loss.\n",
    "    \n",
    "    Args:\n",
    "        model: модель для обучения\n",
    "        dm: DataModule\n",
    "        class_weights: веса классов для weighted loss (numpy array или None)\n",
    "        max_epochs: количество эпох\n",
    "        lr: learning rate\n",
    "        optimizer_type: тип оптимизатора ('adam', 'adamw', 'sgd')\n",
    "    \n",
    "    Returns:\n",
    "        dict с метриками\n",
    "    \"\"\"\n",
    "    # TODO: Создайте loss function\n",
    "    # Если class_weights не None, используйте nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights))\n",
    "    # Иначе используйте обычный nn.CrossEntropyLoss()\n",
    "    loss_fn = None  # TODO\n",
    "    \n",
    "    lightning_model = BaseLightningModule(\n",
    "        model=model,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer_type=optimizer_type,\n",
    "        learning_rate=lr,\n",
    "        task_type='multiclass'\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        enable_checkpointing=False,\n",
    "        logger=False,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=False\n",
    "    )\n",
    "    trainer.fit(lightning_model, dm)\n",
    "    \n",
    "    metrics = trainer.callback_metrics\n",
    "    return {\n",
    "        'val_acc': metrics.get('val_accuracy', 0).item(),\n",
    "        'val_f1': metrics.get('val_f1_macro', 0).item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Итоговая модель\n",
    "\n",
    "Обучите модель с лучшими гиперпараметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Обучите итоговую модель с лучшими гиперпараметрами\n",
    "# final_model = MultiBranchMLP(\n",
    "#     input_dim=dm.input_dim,\n",
    "#     hidden_dim=best_hidden_dim,\n",
    "#     output_dim=dm.n_classes,\n",
    "#     num_blocks=best_depth,\n",
    "#     dropout=0.1,\n",
    "#     combine_mode='concat'\n",
    "# )\n",
    "\n",
    "# final_results = train_model(\n",
    "#     final_model,\n",
    "#     dm,\n",
    "#     class_weights=class_weights,\n",
    "#     max_epochs=100,\n",
    "#     lr=best_lr,\n",
    "#     optimizer_type=best_optimizer\n",
    "# )\n",
    "\n",
    "# print(f'\\n=== Итоговые результаты ===')\n",
    "# print(f\"F1 score: {final_results['val_f1']:.4f}\")\n",
    "# print(f\"Accuracy: {final_results['val_acc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
