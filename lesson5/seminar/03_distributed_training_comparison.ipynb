{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Å—Ä–∞–≤–Ω–∏–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä—ë—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –æ–±—É—á–µ–Ω–∏—è:\n",
    "\n",
    "1. **Single GPU (Baseline)** - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π GPU\n",
    "2. **DistributedDataParallel (DDP)** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º—ã –∑–∞–ø—É—Å—Ç–∏–º –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫ –∏ –≤—ã–≤–µ–¥–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
    "\n",
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:** 10 —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.\n",
    "\n",
    "**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –î–ª—è DDP —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.profilers import SimpleProfiler\n",
    "import time\n",
    "\n",
    "from text_features_data import TextFeaturesDataModule\n",
    "from mlp_model import DeepMLP\n",
    "from lightning_module import TextClassificationModule\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ GPU (–±–µ–∑ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ CUDA –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)\n",
    "# –í–ê–ñ–ù–û: –Ω–µ –≤—ã–∑—ã–≤–∞–µ–º torch.cuda.get_device_name() –∏ get_device_properties()\n",
    "# —á—Ç–æ–±—ã –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å CUDA –¥–æ —Å–æ–∑–¥–∞–Ω–∏—è DDP –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
    "num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs available: {num_gpus}\")\n",
    "\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU, —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–æ—Å–ª–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å DDP:\n",
    "# if torch.cuda.is_available():\n",
    "#     for i in range(num_gpus):\n",
    "#         print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "#         print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        \n",
    "if num_gpus < 2:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: –î–ª—è DataParallel –∏ DDP —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 2 GPU.\")\n",
    "    print(\"   –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã 2 –∏ 3 –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –∏–ª–∏ –Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç AG News —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache...\n",
      "Dataset loaded: classes=4, features=20005, train=108460, val=19140\n",
      "\n",
      "Dataset info:\n",
      "  Input dim: 20005\n",
      "  Num classes: 4\n",
      "  Train samples: 108460\n",
      "  Val samples: 19140\n",
      "  Batch size: 256\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º DataModule —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏\n",
    "dm = TextFeaturesDataModule(\n",
    "    max_features=20000,\n",
    "    batch_size=256,\n",
    "    use_bigrams=True,\n",
    "    cache_dir=\"./cache\",\n",
    "    num_workers=4,\n",
    "    pin_memory=True,  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU\n",
    ")\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "print(f\"\\nDataset info:\")\n",
    "print(f\"  Input dim: {dm.input_dim}\")\n",
    "print(f\"  Num classes: {dm.n_classes}\")\n",
    "print(f\"  Train samples: {len(dm.train_dataset)}\")\n",
    "print(f\"  Val samples: {len(dm.val_dataset)}\")\n",
    "print(f\"  Batch size: {dm.batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 1: Single GPU (Baseline)\n",
    "\n",
    "–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–π GPU - baseline –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "# model_1 = DeepMLP(\n",
    "#     input_dim=dm.input_dim,\n",
    "#     output_dim=dm.n_classes,\n",
    "#     hidden_dims=[2048, 1024, 512, 256, 128],\n",
    "#     activation='silu',\n",
    "#     dropout=0.3,\n",
    "#     use_batch_norm=True,\n",
    "# )\n",
    "\n",
    "# lightning_model_1 = TextClassificationModule(\n",
    "#     model=model_1,\n",
    "#     lr=1e-3,\n",
    "#     optimizer_type='adam',\n",
    "#     weight_decay=1e-5,\n",
    "#     num_classes=dm.n_classes,\n",
    "# )\n",
    "\n",
    "# # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫\n",
    "# profiler_1 = SimpleProfiler(dirpath='./profiler', filename='exp1_single_gpu')\n",
    "\n",
    "# # Trainer - Single GPU\n",
    "# trainer_1 = pl.Trainer(\n",
    "#     max_epochs=10,\n",
    "#     accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "#     devices=1,  # –û–¥–Ω–∞ GPU\n",
    "#     profiler=profiler_1,\n",
    "#     enable_progress_bar=True,\n",
    "# )\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 1: Single GPU (Baseline)\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"Strategy: Single Device\")\n",
    "# print(f\"Devices: 1 GPU\")\n",
    "\n",
    "# # –û–±—É—á–µ–Ω–∏–µ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏ (–±–µ–∑ CUDA —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å DDP)\n",
    "# start_time = time.time()\n",
    "\n",
    "# trainer_1.fit(lightning_model_1, dm)\n",
    "\n",
    "# training_time_1 = time.time() - start_time\n",
    "\n",
    "# print(f\"\\n‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {training_time_1:.2f} —Å–µ–∫—É–Ω–¥ ({training_time_1/60:.2f} –º–∏–Ω—É—Ç)\")\n",
    "\n",
    "# # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ (—É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ Python –æ–±—ä–µ–∫—Ç—ã)\n",
    "# del model_1, lightning_model_1, trainer_1\n",
    "# # –ù–µ –≤—ã–∑—ã–≤–∞–µ–º torch.cuda.empty_cache() —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ CUDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–∞\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–§–ò–õ–ò–†–û–í–©–ò–ö–ê - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 1\")\n",
    "# print(\"=\"*80 + \"\\n\")\n",
    "# print(profiler_1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2: DistributedDataParallel (DDP)\n",
    "\n",
    "DDP - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:\n",
    "- –ö–∞–∂–¥–∞—è GPU –∏–º–µ–µ—Ç —Å–≤–æ—é –∫–æ–ø–∏—é –º–æ–¥–µ–ª–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "- –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É—é—Ç—Å—è –º–µ–∂–¥—É GPU\n",
    "- –ë–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏\n",
    "- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω –æ–±—É—á–µ–Ω–∏—è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 3: DistributedDataParallel (DDP)\n",
      "================================================================================\n",
      "Strategy: DDP\n",
      "Devices: 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA L40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "You are using a CUDA device ('NVIDIA L40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache...Loading from cache...\n",
      "\n",
      "Dataset loaded: classes=4, features=20005, train=108460, val=19140\n",
      "Dataset loaded: classes=4, features=20005, train=108460, val=19140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | DeepMLP            | 43.8 M | train\n",
      "1 | criterion | CrossEntropyLoss   | 0      | train\n",
      "2 | train_acc | MulticlassAccuracy | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "4 | val_f1    | MulticlassF1Score  | 0      | train\n",
      "---------------------------------------------------------\n",
      "43.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "43.8 M    Total params\n",
      "175.072   Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/venvs/train_py10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n",
      "/home/tam2511/mounts/0/arcadia/market/robotics/cv/ml/user_data/shad/dl2025/lesson5/seminar/text_features_data.py:45: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  x = torch.FloatTensor(self.X[idx])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b59ac0bb094566a589918fdce9a4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tam2511/venvs/train_py10/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ 106.98 —Å–µ–∫—É–Ω–¥ (1.78 –º–∏–Ω—É—Ç)\n"
     ]
    }
   ],
   "source": [
    "if num_gpus >= 2:\n",
    "    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "    model_3 = DeepMLP(\n",
    "        input_dim=dm.input_dim,\n",
    "        output_dim=dm.n_classes,\n",
    "        hidden_dims=[2048, 1024, 512, 256, 128],\n",
    "        activation='silu',\n",
    "        dropout=0.3,\n",
    "        use_batch_norm=True,\n",
    "    )\n",
    "\n",
    "    lightning_model_3 = TextClassificationModule(\n",
    "        model=model_3,\n",
    "        lr=1e-3,\n",
    "        optimizer_type='adam',\n",
    "        weight_decay=1e-5,\n",
    "        num_classes=dm.n_classes,\n",
    "    )\n",
    "\n",
    "    # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫\n",
    "    profiler_3 = SimpleProfiler(dirpath='./profiler', filename='exp3_ddp')\n",
    "\n",
    "    # Trainer - DDP\n",
    "    trainer_3 = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator='gpu',\n",
    "        devices=num_gpus,  # –í—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ GPU\n",
    "        strategy='ddp_notebook',  # DistributedDataParallel\n",
    "        profiler=profiler_3,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 3: DistributedDataParallel (DDP)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Strategy: DDP\")\n",
    "    print(f\"Devices: {num_gpus} GPUs\")\n",
    "\n",
    "    # –û–±—É—á–µ–Ω–∏–µ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏ (–±–µ–∑ CUDA —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏)\n",
    "    start_time = time.time()\n",
    "\n",
    "    trainer_3.fit(lightning_model_3, dm)\n",
    "\n",
    "    training_time_3 = time.time() - start_time\n",
    "\n",
    "    print(f\"\\n‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {training_time_3:.2f} —Å–µ–∫—É–Ω–¥ ({training_time_3/60:.2f} –º–∏–Ω—É—Ç)\")\n",
    "\n",
    "    # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ (—É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ Python –æ–±—ä–µ–∫—Ç—ã)\n",
    "    del model_3, lightning_model_3, trainer_3\n",
    "    # –ù–µ –≤—ã–∑—ã–≤–∞–µ–º torch.cuda.empty_cache() —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ CUDA\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 3: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –¥–ª—è DDP\")\n",
    "    training_time_3 = None\n",
    "    profiler_3 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–§–ò–õ–ò–†–û–í–©–ò–ö–ê - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 3\n",
      "================================================================================\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if num_gpus >= 2 and profiler_3 is not None:\n",
    "    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–∞\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–§–ò–õ–ò–†–û–í–©–ò–ö–ê - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 3\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    print(profiler_3.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_py10",
   "language": "python",
   "name": "train_py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
