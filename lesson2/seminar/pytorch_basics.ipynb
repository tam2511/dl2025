{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Основы PyTorch: эксперименты с примитивами\n",
        "\n",
        "В этом ноутбуке мы поэкспериментируем с основными компонентами PyTorch и увидим как они работают в разных режимах\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Тензоры (Tensors)\n",
        "\n",
        "Тензор - основная структура данных в PyTorch, аналог numpy array, но с поддержкой GPU и автоматического дифференцирования\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Создание тензоров разными способами\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1 = torch.tensor([1, 2, 3, 4, 5])\n",
        "x2 = torch.zeros(3, 4)\n",
        "x3 = torch.ones(2, 3)\n",
        "x4 = torch.randn(2, 3)\n",
        "x5 = torch.arange(0, 10, 2)\n",
        "x6 = torch.linspace(0, 1, 5)\n",
        "\n",
        "print(\"Из списка:\", x1)\n",
        "print(\"\\nНули:\", x2)\n",
        "print(\"\\nЕдиницы:\", x3)\n",
        "print(\"\\nСлучайные (нормальное распределение):\", x4)\n",
        "print(\"\\nПоследовательность:\", x5)\n",
        "print(\"\\nЛинейное пространство:\", x6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Типы данных (dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "float32_tensor = torch.tensor([1.0, 2.0], dtype=torch.float32)\n",
        "float64_tensor = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
        "int_tensor = torch.tensor([1, 2], dtype=torch.int32)\n",
        "long_tensor = torch.tensor([1, 2], dtype=torch.long)\n",
        "bool_tensor = torch.tensor([True, False], dtype=torch.bool)\n",
        "\n",
        "print(f\"float32: {float32_tensor}, dtype={float32_tensor.dtype}, размер={float32_tensor.element_size()} байт\")\n",
        "print(f\"float64: {float64_tensor}, dtype={float64_tensor.dtype}, размер={float64_tensor.element_size()} байт\")\n",
        "print(f\"int32: {int_tensor}, dtype={int_tensor.dtype}\")\n",
        "print(f\"int64/long: {long_tensor}, dtype={long_tensor.dtype}\")\n",
        "print(f\"bool: {bool_tensor}, dtype={bool_tensor.dtype}\")\n",
        "\n",
        "converted = int_tensor.float()\n",
        "print(f\"\\nКонвертация int -> float: {converted}, dtype={converted.dtype}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Устройства (Device): CPU vs GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cpu_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"CPU тензор: device={cpu_tensor.device}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Доступное устройство: {device}\")\n",
        "\n",
        "gpu_tensor = cpu_tensor.to(device)\n",
        "print(f\"GPU тензор: device={gpu_tensor.device}\")\n",
        "\n",
        "back_to_cpu = gpu_tensor.cpu()\n",
        "print(f\"Обратно на CPU: device={back_to_cpu.device}\")\n",
        "\n",
        "direct_gpu = torch.randn(3, 3, device=device)\n",
        "print(f\"\\nСоздание сразу на устройстве: device={direct_gpu.device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Autograd: автоматическое дифференцирование\n",
        "\n",
        "Autograd - система автоматического вычисления градиентов, основа обучения нейросетей\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Базовый пример: вычисление градиента\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2 + 3 * x + 1\n",
        "print(f\"x = {x.item()}\")\n",
        "print(f\"y = x^2 + 3x + 1 = {y.item()}\")\n",
        "print(f\"requires_grad: x={x.requires_grad}, y={y.requires_grad}\")\n",
        "\n",
        "y.backward()\n",
        "print(f\"\\nГрадиент dy/dx = 2x + 3 = {x.grad.item()}\")\n",
        "print(f\"Проверка: 2*{x.item()} + 3 = {2*x.item() + 3}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Градиенты для векторов и матриц\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "w = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "x = torch.tensor([2.0, 1.0, 0.5])\n",
        "z = torch.dot(w, x)\n",
        "print(f\"w = {w}\")\n",
        "print(f\"x = {x}\")\n",
        "print(f\"z = w·x = {z.item()}\")\n",
        "\n",
        "z.backward()\n",
        "print(f\"\\nГрадиент dz/dw = x = {w.grad}\")\n",
        "\n",
        "w.grad.zero_()\n",
        "loss = (w ** 2).sum()\n",
        "loss.backward()\n",
        "print(f\"\\nДругой пример: loss = sum(w^2) = {loss.item()}\")\n",
        "print(f\"Градиент dloss/dw = 2w = {w.grad}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### torch.no_grad(): отключение градиентов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "\n",
        "b = a * 2\n",
        "print(f\"С градиентами: b.requires_grad = {b.requires_grad}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    c = a * 2\n",
        "    print(f\"Без градиентов: c.requires_grad = {c.requires_grad}\")\n",
        "\n",
        "d = a.detach() * 2\n",
        "print(f\"После detach: d.requires_grad = {d.requires_grad}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset и DataLoader\n",
        "\n",
        "Механизм загрузки и батчирования данных в PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Создание своего Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, size=100):\n",
        "        self.X = torch.randn(size, 5)\n",
        "        self.y = torch.randint(0, 2, (size,))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = SimpleDataset(size=20)\n",
        "print(f\"Размер датасета: {len(dataset)}\")\n",
        "print(f\"\\nПервый пример:\")\n",
        "x, y = dataset[0]\n",
        "print(f\"  X shape: {x.shape}, y: {y}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader: разные режимы работы\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = SimpleDataset(size=10)\n",
        "\n",
        "print(\"=== Без shuffle, batch_size=3 ===\")\n",
        "loader1 = DataLoader(dataset, batch_size=3, shuffle=False)\n",
        "for i, (X_batch, y_batch) in enumerate(loader1):\n",
        "    print(f\"Batch {i}: X shape={X_batch.shape}, y={y_batch.tolist()}\")\n",
        "\n",
        "print(\"\\n=== С shuffle, batch_size=3 ===\")\n",
        "loader2 = DataLoader(dataset, batch_size=3, shuffle=True)\n",
        "for i, (X_batch, y_batch) in enumerate(loader2):\n",
        "    print(f\"Batch {i}: X shape={X_batch.shape}, y={y_batch.tolist()}\")\n",
        "\n",
        "print(\"\\n=== drop_last=True (отбрасывает неполный батч) ===\")\n",
        "loader3 = DataLoader(dataset, batch_size=3, drop_last=True)\n",
        "print(f\"Количество батчей с drop_last=True: {len(loader3)}\")\n",
        "\n",
        "print(\"\\n=== drop_last=False (по умолчанию) ===\")\n",
        "loader4 = DataLoader(dataset, batch_size=3, drop_last=False)\n",
        "print(f\"Количество батчей с drop_last=False: {len(loader4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. torch.nn: слои и модули\n",
        "\n",
        "Готовые блоки для построения нейронных сетей\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Основные слои\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linear = nn.Linear(in_features=5, out_features=3)\n",
        "x = torch.randn(2, 5)\n",
        "output = linear(x)\n",
        "print(f\"Linear: input {x.shape} -> output {output.shape}\")\n",
        "print(f\"Веса: {linear.weight.shape}, Bias: {linear.bias.shape}\")\n",
        "\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "x_img = torch.randn(1, 3, 28, 28)\n",
        "output = conv(x_img)\n",
        "print(f\"\\nConv2d: input {x_img.shape} -> output {output.shape}\")\n",
        "\n",
        "dropout = nn.Dropout(p=0.5)\n",
        "x = torch.ones(3, 4)\n",
        "print(f\"\\nБез Dropout:\\n{x}\")\n",
        "dropout.train()\n",
        "print(f\"С Dropout (train mode, p=0.5):\\n{dropout(x)}\")\n",
        "dropout.eval()\n",
        "print(f\"С Dropout (eval mode):\\n{dropout(x)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Функции активации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.linspace(-3, 3, 100)\n",
        "\n",
        "relu = nn.ReLU()\n",
        "sigmoid = nn.Sigmoid()\n",
        "tanh = nn.Tanh()\n",
        "leaky_relu = nn.LeakyReLU(negative_slope=0.1)\n",
        "\n",
        "plt.figure(figsize=(15, 4))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.plot(x.numpy(), relu(x).numpy())\n",
        "plt.title('ReLU')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.plot(x.numpy(), sigmoid(x).numpy())\n",
        "plt.title('Sigmoid')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.plot(x.numpy(), tanh(x).numpy())\n",
        "plt.title('Tanh')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.plot(x.numpy(), leaky_relu(x).numpy())\n",
        "plt.title('LeakyReLU')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Создание моделей: разные подходы\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1 = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 2)\n",
        ")\n",
        "print(\"=== Sequential ===\")\n",
        "print(model1)\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model2 = CustomModel(10, 20, 2)\n",
        "print(\"\\n=== Custom Module ===\")\n",
        "print(model2)\n",
        "\n",
        "x = torch.randn(5, 10)\n",
        "print(f\"\\nВход: {x.shape}\")\n",
        "print(f\"Выход model1: {model1(x).shape}\")\n",
        "print(f\"Выход model2: {model2(x).shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Функции потерь (Loss Functions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = torch.randn(3, 5)\n",
        "targets_class = torch.tensor([1, 0, 4])\n",
        "targets_values = torch.randn(3, 5)\n",
        "\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "loss_ce = ce_loss(predictions, targets_class)\n",
        "print(f\"CrossEntropyLoss (для классификации): {loss_ce.item():.4f}\")\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "loss_mse = mse_loss(predictions, targets_values)\n",
        "print(f\"MSELoss (для регрессии): {loss_mse.item():.4f}\")\n",
        "\n",
        "mae_loss = nn.L1Loss()\n",
        "loss_mae = mae_loss(predictions, targets_values)\n",
        "print(f\"L1Loss/MAE (для регрессии): {loss_mae.item():.4f}\")\n",
        "\n",
        "print(\"\\n=== Reduction modes ===\")\n",
        "mse_none = nn.MSELoss(reduction='none')\n",
        "mse_mean = nn.MSELoss(reduction='mean')\n",
        "mse_sum = nn.MSELoss(reduction='sum')\n",
        "\n",
        "pred = torch.tensor([1.0, 2.0, 3.0])\n",
        "target = torch.tensor([1.5, 2.5, 2.0])\n",
        "\n",
        "print(f\"none (поэлементно): {mse_none(pred, target)}\")\n",
        "print(f\"mean (среднее): {mse_mean(pred, target).item():.4f}\")\n",
        "print(f\"sum (сумма): {mse_sum(pred, target).item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Оптимизаторы (Optimizers)\n",
        "\n",
        "Разные алгоритмы оптимизации для обновления весов\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Разные оптимизаторы и их параметры\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Linear(10, 2)\n",
        "\n",
        "sgd = optim.SGD(model.parameters(), lr=0.01)\n",
        "print(f\"SGD: {sgd}\")\n",
        "\n",
        "sgd_momentum = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "print(f\"\\nSGD с momentum: {sgd_momentum}\")\n",
        "\n",
        "adam = optim.Adam(model.parameters(), lr=0.001)\n",
        "print(f\"\\nAdam: {adam}\")\n",
        "\n",
        "adamw = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "print(f\"\\nAdamW (с weight decay): {adamw}\")\n",
        "\n",
        "rmsprop = optim.RMSprop(model.parameters(), lr=0.01)\n",
        "print(f\"\\nRMSprop: {rmsprop}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Сравнение оптимизаторов на простой задаче\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_with_optimizer(optimizer_class, lr, name, epochs=50):\n",
        "    model = nn.Sequential(nn.Linear(2, 10), nn.ReLU(), nn.Linear(10, 1))\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    X = torch.randn(100, 2)\n",
        "    y = (X[:, 0] ** 2 + X[:, 1] ** 2).unsqueeze(1)\n",
        "    \n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X)\n",
        "        loss = criterion(predictions, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    \n",
        "    return losses\n",
        "\n",
        "sgd_losses = train_with_optimizer(optim.SGD, lr=0.01, name='SGD')\n",
        "sgd_momentum_losses = train_with_optimizer(lambda params, lr: optim.SGD(params, lr=lr, momentum=0.9), lr=0.01, name='SGD+Momentum')\n",
        "adam_losses = train_with_optimizer(optim.Adam, lr=0.01, name='Adam')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(sgd_losses, label='SGD')\n",
        "plt.plot(sgd_momentum_losses, label='SGD + Momentum')\n",
        "plt.plot(adam_losses, label='Adam')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Сравнение оптимизаторов')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Влияние Learning Rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rates = [0.001, 0.01, 0.1, 1.0]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "for lr in learning_rates:\n",
        "    losses = train_with_optimizer(optim.SGD, lr=lr, name=f'LR={lr}', epochs=50)\n",
        "    plt.plot(losses, label=f'LR={lr}')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Влияние Learning Rate на обучение')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Режимы train() и eval()\n",
        "\n",
        "Некоторые слои ведут себя по-разному в режимах обучения и инференса\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelWithDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(10, 10)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "model = ModelWithDropout()\n",
        "x = torch.ones(3, 10)\n",
        "\n",
        "print(\"=== Train mode ===\")\n",
        "model.train()\n",
        "print(\"Первый проход:\")\n",
        "print(model(x)[0, :5])\n",
        "print(\"Второй проход (разные значения из-за dropout):\")\n",
        "print(model(x)[0, :5])\n",
        "\n",
        "print(\"\\n=== Eval mode ===\")\n",
        "model.eval()\n",
        "print(\"Первый проход:\")\n",
        "print(model(x)[0, :5])\n",
        "print(\"Второй проход (одинаковые значения, dropout отключен):\")\n",
        "print(model(x)[0, :5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Полный пример: собираем все вместе\n",
        "\n",
        "Минимальный пример обучения нейросети от начала до конца\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, n_samples=1000):\n",
        "        self.X = torch.randn(n_samples, 20)\n",
        "        self.y = (self.X[:, 0] + self.X[:, 1] > 0).long()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = ToyDataset(800)\n",
        "test_dataset = ToyDataset(200)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(20, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 2)\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "test_accs = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    train_losses.append(epoch_loss / len(train_loader))\n",
        "    \n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += y_batch.size(0)\n",
        "            correct += (predicted == y_batch).sum().item()\n",
        "    \n",
        "    test_acc = correct / total\n",
        "    test_accs.append(test_acc)\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_losses[-1]:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(test_accs)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Test Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
