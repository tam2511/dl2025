{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Создание нейросети с помощью NumPy\n",
        "\n",
        "В этом ноутбуке мы:\n",
        "1. Реализуем простой нейрон используя NumPy\n",
        "2. Вычислим производные для обратного распространения\n",
        "3. Создадим класс слоя, который сохраняет состояния необходимые для прямого и обратного прохода\n",
        "4. Создадим нейросеть из нескольких слоев\n",
        "5. Обучим сеть на простой задаче\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Реализация простого нейрона\n",
        "\n",
        "Нейрон выполняет следующую операцию:\n",
        "$$y = \\sigma(w^T x + b)$$\n",
        "\n",
        "где:\n",
        "- $x$ - входной вектор\n",
        "- $w$ - вектор весов\n",
        "- $b$ - смещение\n",
        "- $\\sigma$ - функция активации (будем использовать сигмоиду)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def neuron_forward(x, w, b):\n",
        "    z = np.dot(w, x) + b\n",
        "    output = sigmoid(z)\n",
        "    return output\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0])\n",
        "w = np.array([0.5, -0.2, 0.1])\n",
        "b = 0.3\n",
        "\n",
        "output = neuron_forward(x, w, b)\n",
        "print(f\"Input: {x}\")\n",
        "print(f\"Weights: {w}\")\n",
        "print(f\"Bias: {b}\")\n",
        "print(f\"Output: {output:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Вычисление производных для обратного распространения\n",
        "\n",
        "Для обратного распространения нам нужно вычислить градиенты:\n",
        "\n",
        "**Производная сигмоиды:**\n",
        "$$\\frac{\\partial \\sigma}{\\partial z} = \\sigma(z) \\cdot (1 - \\sigma(z))$$\n",
        "\n",
        "**Градиенты по параметрам:**\n",
        "- $\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial w} = \\frac{\\partial L}{\\partial y} \\cdot \\sigma'(z) \\cdot x$\n",
        "- $\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial b} = \\frac{\\partial L}{\\partial y} \\cdot \\sigma'(z)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid_derivative(z):\n",
        "    s = sigmoid(z)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def neuron_backward(x, w, b, dy):\n",
        "    z = np.dot(w, x) + b\n",
        "    dz = dy * sigmoid_derivative(z)\n",
        "    dw = dz * x\n",
        "    db = dz\n",
        "    dx = dz * w\n",
        "    return dw, db, dx\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0])\n",
        "w = np.array([0.5, -0.2, 0.1])\n",
        "b = 0.3\n",
        "dy = 1.0\n",
        "\n",
        "dw, db, dx = neuron_backward(x, w, b, dy)\n",
        "print(f\"Gradient w.r.t. weights: {dw}\")\n",
        "print(f\"Gradient w.r.t. bias: {db:.4f}\")\n",
        "print(f\"Gradient w.r.t. input: {dx}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Класс слоя нейронов с управлением состоянием\n",
        "\n",
        "Теперь создадим класс слоя, который:\n",
        "- Содержит несколько нейронов (принимает n_features входов и возвращает n_outputs выходов)\n",
        "- Хранит параметры (матрицу весов и вектор смещений)\n",
        "- Кэширует промежуточные значения во время прямого прохода\n",
        "- Использует кэшированные значения для эффективного обратного прохода\n",
        "- Реализует обновление параметров\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "        self.W = np.random.randn(n_inputs, n_outputs) * 0.01\n",
        "        self.b = np.zeros(n_outputs)\n",
        "        self.cache = {}\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = np.dot(x, self.W) + self.b\n",
        "        output = sigmoid(z)\n",
        "        self.cache['x'] = x\n",
        "        self.cache['z'] = z\n",
        "        self.cache['output'] = output\n",
        "        return output\n",
        "    \n",
        "    def backward(self, dy):\n",
        "        x = self.cache['x']\n",
        "        output = self.cache['output']\n",
        "        dz = dy * output * (1 - output)\n",
        "        \n",
        "        if x.ndim == 1:\n",
        "            self.dW = np.outer(x, dz)\n",
        "            self.db = dz\n",
        "            dx = np.dot(dz, self.W.T)\n",
        "        else:\n",
        "            batch_size = x.shape[0]\n",
        "            self.dW = np.dot(x.T, dz) / batch_size\n",
        "            self.db = np.mean(dz, axis=0)\n",
        "            dx = np.dot(dz, self.W.T)\n",
        "        \n",
        "        return dx\n",
        "    \n",
        "    def update_parameters(self, learning_rate):\n",
        "        self.W -= learning_rate * self.dW\n",
        "        self.b -= learning_rate * self.db\n",
        "    \n",
        "    def get_parameters(self):\n",
        "        return {'W': self.W.copy(), 'b': self.b.copy()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Пример использования класса\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layer = Layer(n_inputs=3, n_outputs=2)\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0])\n",
        "output = layer.forward(x)\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Output: {output}\")\n",
        "\n",
        "dy = np.ones(2)\n",
        "dx = layer.backward(dy)\n",
        "print(f\"Градиент по входу: {dx}\")\n",
        "\n",
        "layer.update_parameters(learning_rate=0.1)\n",
        "params = layer.get_parameters()\n",
        "print(f\"Размер матрицы весов: {params['W'].shape}\")\n",
        "print(f\"Размер вектора смещений: {params['b'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Создание нейросети из нескольких слоев\n",
        "\n",
        "Теперь создадим класс нейросети, которая будет:\n",
        "- Состоять из нескольких слоев\n",
        "- Последовательно выполнять прямой проход через все слои\n",
        "- Последовательно выполнять обратный проход через все слои (в обратном порядке)\n",
        "- Обновлять параметры всех слоев\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_sizes):\n",
        "        self.layers = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            layer = Layer(layer_sizes[i], layer_sizes[i + 1])\n",
        "            self.layers.append(layer)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = x\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(output)\n",
        "        return output\n",
        "    \n",
        "    def backward(self, dy):\n",
        "        dx = dy\n",
        "        for layer in reversed(self.layers):\n",
        "            dx = layer.backward(dx)\n",
        "        return dx\n",
        "    \n",
        "    def update_parameters(self, learning_rate):\n",
        "        for layer in self.layers:\n",
        "            layer.update_parameters(learning_rate)\n",
        "    \n",
        "    def get_all_parameters(self):\n",
        "        params = []\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            params.append({\n",
        "                'layer': i,\n",
        "                'parameters': layer.get_parameters()\n",
        "            })\n",
        "        return params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Пример использования нейросети\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network = NeuralNetwork([4, 8, 3, 1])\n",
        "\n",
        "print(\"Архитектура сети:\")\n",
        "for i, layer in enumerate(network.layers):\n",
        "    print(f\"  Слой {i+1}: {layer.n_inputs} -> {layer.n_outputs}\")\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0, 4.0])\n",
        "output = network.forward(x)\n",
        "print(f\"\\nВход: {x}\")\n",
        "print(f\"Выход сети: {output}\")\n",
        "\n",
        "dy = np.array([1.0])\n",
        "dx = network.backward(dy)\n",
        "print(f\"\\nГрадиент по входу: {dx}\")\n",
        "\n",
        "network.update_parameters(learning_rate=0.01)\n",
        "print(\"\\nПараметры обновлены!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Обучение сети на простой задаче\n",
        "\n",
        "Обучим сеть предсказывать простую функцию\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mse_loss(y_pred, y_true):\n",
        "    return np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "def mse_loss_grad(y_pred, y_true):\n",
        "    return 2 * (y_pred - y_true) / y_true.size\n",
        "\n",
        "X_train = np.array([\n",
        "    [0.0, 0.0],\n",
        "    [0.0, 1.0],\n",
        "    [1.0, 0.0],\n",
        "    [1.0, 1.0]\n",
        "])\n",
        "\n",
        "y_train = np.array([[0.0], [1.0], [1.0], [0.0]])\n",
        "\n",
        "network = NeuralNetwork([2, 4, 1])\n",
        "\n",
        "losses = []\n",
        "epochs = 1000\n",
        "learning_rate = 0.5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for i in range(len(X_train)):\n",
        "        x = X_train[i]\n",
        "        y_true = y_train[i]\n",
        "        \n",
        "        y_pred = network.forward(x)\n",
        "        loss = mse_loss(y_pred, y_true)\n",
        "        total_loss += loss\n",
        "        \n",
        "        grad = mse_loss_grad(y_pred, y_true)\n",
        "        network.backward(grad)\n",
        "        network.update_parameters(learning_rate)\n",
        "    \n",
        "    avg_loss = total_loss / len(X_train)\n",
        "    losses.append(avg_loss)\n",
        "    \n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"\\nПредсказания после обучения:\")\n",
        "for i in range(len(X_train)):\n",
        "    pred = network.forward(X_train[i])\n",
        "    print(f\"  {X_train[i]} -> {pred[0]:.4f} (истинное: {y_train[i][0]})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Кривая обучения')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
